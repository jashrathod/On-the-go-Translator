{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import pyaudio\n",
    "import simpleaudio as sa\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as MFCC\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAY SOMETHING...\n",
      "TIME OVER, THANKS!\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print('SAY SOMETHING...')\n",
    "    audio = r.listen(source)\n",
    "    print('TIME OVER, THANKS!')\n",
    "\n",
    "with open(\"microphone-results.wav\", \"wb\") as f:\n",
    "    f.write(audio.get_wav_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n"
     ]
    }
   ],
   "source": [
    "def get_MFCC(sr,audio):\n",
    "    features = MFCC.mfcc(audio,sr,0.025,0.01,13,appendEnergy=False)\n",
    "    feat = np.asarray(())\n",
    "\n",
    "    for i in range(features.shape[0]):\n",
    "        temp = features[i,:]\n",
    "        if np.isnan(np.min(temp)):\n",
    "            continue\n",
    "        else:\n",
    "            if feat.size == 0 :\n",
    "                feat = temp\n",
    "            else:\n",
    "                feat = np.vstack((feat,temp))\n",
    "    \n",
    "    features = feat\n",
    "    features = preprocessing.scale(features)\n",
    "    return features                \n",
    "\n",
    "def gmm_model():\n",
    "    sourcePath = \"/Users/jashrathod/PycharmProjects/On-the-go-Translator/\" \n",
    "    modelPath = \"/Users/jashrathod/PycharmProjects/On-the-go-Translator/Voice-Based-Gender-Detection/Modules/\"\n",
    "\n",
    "    gmmFiles = [os.path.join(modelPath,fname) for fname in os.listdir(modelPath) if fname.endswith('.gmm')]\n",
    "    models = [cPickle.load(open(fname,'rb')) for fname in gmmFiles]\n",
    "    # print(models)\n",
    "\n",
    "    genders = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname in gmmFiles]\n",
    "    files = [os.path.join(sourcePath,f) for f in os.listdir(sourcePath) if f.endswith(\".wav\")]\n",
    "\n",
    "    # for f in files:\n",
    "\n",
    "    f = sourcePath + \"microphone-results.wav\"\n",
    "#     print(f.split(\"/\")[-1])\n",
    "    sr,audio = read(f)\n",
    "    features = get_MFCC(sr,audio)\n",
    "    scores = None\n",
    "    log_likelihood = np.zeros(len(models))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]\n",
    "        scores = np.array(gmm.score(features))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "       \n",
    "    winner = np.argmax(log_likelihood)\n",
    "    winner = (winner+1)%2\n",
    "    print(genders[winner])\n",
    "\n",
    "gmm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  I am going home\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    text_audio = r.recognize_google(audio)\n",
    "    print(\"text: \", text_audio)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected(lang=en, confidence=1.0)\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "dt1 = translator.detect(text_audio)\n",
    "print(dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"hi\", \"gu\", \"fr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in l:\n",
    "    translated = translator.translate(text_audio, dest=i)\n",
    "    a = translated.text\n",
    "\n",
    "    speech = gTTS(text=a, lang=i, slow=False)\n",
    "\n",
    "    speech.save(\"text-\" + i + \".wav\")\n",
    "#     os.system(\"start text-\" + i + \".mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import parselmouth\n",
    "# from parselmouth.praat import call\n",
    "\n",
    "# sound = parselmouth.Sound(\"text-hi.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation = call(sound, \"To Manipulation\", 0.001, 75, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitch_tier = call(manipulation, \"Extract pitch tier\")\n",
    "\n",
    "# call(pitch_tier, \"Multiply frequencies\", sound.xmin, sound.xmax, 1)\n",
    "# # print(sound.xmin, sound.xmax)\n",
    "\n",
    "# call([pitch_tier, manipulation], \"Replace pitch tier\")\n",
    "# sound_octave_up = call(manipulation, \"Get resynthesis (overlap-add)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Audio\n",
    "# Audio(data=sound_octave_up.values, rate=sound_octave_up.sampling_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
